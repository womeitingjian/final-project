{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "import os  \n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "from tqdm import tqdm  \n",
    "import seaborn as sns \n",
    "from pylab import rcParams  \n",
    "import matplotlib.pyplot as plt  \n",
    "from matplotlib import rc  \n",
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "from pandas.plotting import register_matplotlib_converters  \n",
    "from torch import nn, optim \n",
    "import matplotlib\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_excel('E:\\covid-data.xlsx', usecols='A,D',index_col=0,parse_dates=True)\n",
    "df.dropna(inplace=True)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Active Cases'].values.astype(float)\n",
    "\n",
    "test_size = 100\n",
    "window_size = 14\n",
    "\n",
    "train_data = y[:-test_size]\n",
    "test_data = y[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train: {len(train_data)}')\n",
    "print(f'Test:  {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.ylabel('number of infected people')\n",
    "plt.grid(True)\n",
    "plt.autoscale(axis='x',tight=True)\n",
    "plt.plot(df['Active Cases'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "train_norm = scaler.fit_transform(train_data.reshape(-1, 1))\n",
    "test_norm = scaler.fit_transform(test_data.reshape(-1, 1))\n",
    "print(f'First item, original: {train_data[0]}')\n",
    "print(f'First item, scaled:  {train_norm[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dataset(dataset, timestep ):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-timestep -1):\n",
    "        a = dataset[i:(i+timestep )]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + timestep])\n",
    "    return np.array(dataX),np.array(dataY)\n",
    "\n",
    "trainX1,trainY1  = create_dataset(train_norm,window_size)\n",
    "testX1,testY1  = create_dataset(test_norm,window_size)\n",
    "\n",
    "trainX = np.reshape(trainX1, (trainX1.shape[0], trainX1.shape[1], 1))\n",
    "testX = np.reshape(testX1, (testX1.shape[0], testX1.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "#def mape(y_true, y_pred):\n",
    "#    return K.mean(K.abs((y_true - y_pred) / y_true), axis=-1)\n",
    "\n",
    "units =30\n",
    "rate=0.3\n",
    "epochs=50\n",
    "batch_size=64\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model = Sequential()\n",
    "model.add(LSTM(units = units,activation='tanh', input_shape = (None,1)))\n",
    "model.add(Dropout(rate=rate))\n",
    "model.add(Dense(units = 1,activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer,metrics=['mape'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(trainX, trainY1, epochs=epochs, batch_size=batch_size, verbose=1,\n",
    "                        validation_data=(testX, testY1), )  \n",
    "\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='test_loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pre=model.predict(trainX)\n",
    "plt.figure(figsize=(15, 8))\n",
    "train_pre=scaler.inverse_transform(train_pre)\n",
    "trainY1_pre=scaler.inverse_transform(trainY1)\n",
    "plt.plot(range(1363),trainY1_pre,range(1363),train_pre)\n",
    "plt.legend(['true','pre'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pre=model.predict(testX)\n",
    "plt.figure(figsize=(15, 8))\n",
    "test_pre=scaler.inverse_transform(test_pre)\n",
    "testY1_true=scaler.inverse_transform(testY1)\n",
    "plt.plot(range(85),testY1_true,range(85),test_pre)\n",
    "plt.legend(['true','pre'])\n",
    "plt.show()\n",
    "#print(test_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(\n",
    "    df.index[:len(train_data)],\n",
    "    train_data.flatten(),\n",
    "    label='Historical Daily Cases')\n",
    " \n",
    "plt.plot(\n",
    "    df.index[len(train_data):len(train_data) + len(testY1_true)],\n",
    "    testY1_true,\n",
    "    label='Real Daily Cases')\n",
    " \n",
    "plt.plot(\n",
    "    df.index[len(train_data):len(train_data) + len(test_pre)],\n",
    "    test_pre,\n",
    "    label='Predicted Daily Cases')\n",
    " \n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=window_size\n",
    "testpredict=model.predict(testX)[-n-1:-1]\n",
    "\n",
    "a=[]\n",
    "for i in range(len(testpredict)):\n",
    "    a.append(testpredict[i][0])\n",
    "print(a)\n",
    "\n",
    "\n",
    "#预测\n",
    "def Perdict(a,n):\n",
    "    Input=a[-n:]\n",
    "    Input = np.array(Input)\n",
    "    Input = Input.astype('float32')\n",
    "    Input = Input.reshape(-1, 1)\n",
    "\n",
    "    Input = np.reshape(Input[-n:], (Input.shape[0], Input.shape[1], 1))\n",
    "\n",
    "    featruePredict = model.predict(Input)\n",
    "\n",
    "    featruePredict = scaler.inverse_transform(featruePredict)\n",
    "\n",
    "    return featruePredict[0][0]\n",
    "\n",
    "\n",
    "for i in range(len(testpredict)):\n",
    "    t=Perdict(a,n)\n",
    "    a.append(t)\n",
    "    \n",
    "a = a[14:27]\n",
    "print(\"预测结果为：\",a)\n",
    "plt.plot(a)\n",
    "plt.ticklabel_format(style='plain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
